{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "099138b3-6bc2-4a9e-a8de-898db18247ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting chardet\n",
      "  Obtaining dependency information for chardet from https://files.pythonhosted.org/packages/38/6f/f5fbc992a329ee4e0f288c1fe0e2ad9485ed064cac731ed2fe47dcc38cbf/chardet-5.2.0-py3-none-any.whl.metadata\n",
      "  Downloading chardet-5.2.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Downloading chardet-5.2.0-py3-none-any.whl (199 kB)\n",
      "   ---------------------------------------- 0.0/199.4 kB ? eta -:--:--\n",
      "   -- ------------------------------------- 10.2/199.4 kB ? eta -:--:--\n",
      "   -------- ------------------------------ 41.0/199.4 kB 991.0 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 199.4/199.4 kB 2.0 MB/s eta 0:00:00\n",
      "Installing collected packages: chardet\n",
      "Successfully installed chardet-5.2.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install chardet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7ff61af3-c21b-445f-ae4f-99a388d4eb7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "import cv2\n",
    "import chardet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3b4446-b9aa-40a8-959f-8a239bf3da52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b0000523-f419-41d0-a1d4-126bdaf1f173",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:/Users/RD/WorkWork/Prog/Datasets/DatasetFenyaTensorflow/combined/Dataset\\\\Dataset\\\\sorted\\\\EMPTY100.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 61\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;66;03m#копирование файлов\u001b[39;00m\n\u001b[0;32m     60\u001b[0m new_file \u001b[38;5;241m=\u001b[39m shutil\u001b[38;5;241m.\u001b[39mcopy(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(root, file), destination_directoryLabels \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minstance\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(counter) \u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.txt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 61\u001b[0m new_file1 \u001b[38;5;241m=\u001b[39m \u001b[43mshutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile1\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdestination_directoryImages\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minstance\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcounter\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m.jpg\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     62\u001b[0m counter\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     63\u001b[0m new_uid \u001b[38;5;241m=\u001b[39m file1[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m3\u001b[39m]\n",
      "File \u001b[1;32mC:\\Users\\RD\\WorkWork\\Prog\\Python\\Lib\\shutil.py:435\u001b[0m, in \u001b[0;36mcopy\u001b[1;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[0;32m    433\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(dst):\n\u001b[0;32m    434\u001b[0m     dst \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(dst, os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(src))\n\u001b[1;32m--> 435\u001b[0m \u001b[43mcopyfile\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfollow_symlinks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_symlinks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    436\u001b[0m copymode(src, dst, follow_symlinks\u001b[38;5;241m=\u001b[39mfollow_symlinks)\n\u001b[0;32m    437\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dst\n",
      "File \u001b[1;32mC:\\Users\\RD\\WorkWork\\Prog\\Python\\Lib\\shutil.py:260\u001b[0m, in \u001b[0;36mcopyfile\u001b[1;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[0;32m    258\u001b[0m     os\u001b[38;5;241m.\u001b[39msymlink(os\u001b[38;5;241m.\u001b[39mreadlink(src), dst)\n\u001b[0;32m    259\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 260\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m fsrc:\n\u001b[0;32m    261\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    262\u001b[0m             \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(dst, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m fdst:\n\u001b[0;32m    263\u001b[0m                 \u001b[38;5;66;03m# macOS\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:/Users/RD/WorkWork/Prog/Datasets/DatasetFenyaTensorflow/combined/Dataset\\\\Dataset\\\\sorted\\\\EMPTY100.jpg'"
     ]
    }
   ],
   "source": [
    "#обработка датасета\n",
    "\n",
    "dir = ('C:/Users/RD/WorkWork/Prog/Datasets/DatasetFenyaTensorflow/combined/')\n",
    "destination_directoryLabels = ('C:/Users/RD/WorkWork/Prog/Datasets/yolov5/labels_all/')\n",
    "destination_directoryImages = ('C:/Users/RD/WorkWork/Prog/Datasets/yolov5/images_all/')\n",
    "\n",
    "#проверка на правильное расширение файла(опционально)\n",
    "for root, dirs, files in os.walk(dir):\n",
    "    for file in files:\n",
    "        if not \"txt\" in file and not \"jpg\" in file:\n",
    "            os.rename(os.path.join(root, file), os.path.join(root, file)+'.jpg')\n",
    "\n",
    "#сортировка датасета\n",
    "counter = 0\n",
    "doppel_counter = 0\n",
    "new_uid = 0\n",
    "for root, dirs, files in os.walk(dir):\n",
    "    for file in files:\n",
    "        if 'txt' in file:\n",
    "            for roots1, dirs1, files1 in os.walk(dir):\n",
    "                for file1 in files1:\n",
    "                    if 'jpg' in file1 and file[:-3] == file1[:-3]:\n",
    "                        uid = file1[:-3]\n",
    "                        \n",
    "                        #проверка на повторения\n",
    "                        if uid == new_uid: \n",
    "                            print(counter)\n",
    "                            print(uid)\n",
    "                            doppel_counter+=1\n",
    "                        filepath_img = os.path.join(roots1, file1)\n",
    "                        filepath_txt = os.path.join(root, file)\n",
    "                        \n",
    "                        #переформатирование аннотаций \n",
    "                        with open(filepath_txt, 'r', encoding='utf-8') as file: \n",
    "                            content = file.read()\n",
    "                            data = json.loads(content)\n",
    "                            class_name = data['class']\n",
    "                            height = data['rect']['Height']\n",
    "                            top_left_x = data['rect']['TopLeftX']\n",
    "                            top_left_y = data['rect']['TopLeftY']\n",
    "                            width = data['rect']['Width']\n",
    "                        image = cv2.imread(filepath_img)\n",
    "                        img_height, img_width, channels = image.shape\n",
    "                        x_center = (top_left_x + width / 2) / img_width\n",
    "                        y_center = (top_left_y + height / 2) / img_height\n",
    "                        heightN = height / img_height\n",
    "                        widthN = width / img_width\n",
    "                        if class_name == 'sand':\n",
    "                            temp_clas = 2\n",
    "        \n",
    "                        if class_name == 'gravel':\n",
    "                            temp_clas = 1\n",
    "        \n",
    "                        if class_name == 'empty':\n",
    "                            temp_clas = 0\n",
    "                        new_data = f\"{temp_clas} {x_center} {y_center} {widthN} {heightN}\"\n",
    "                        with open(filepath_txt, 'w', encoding='utf-8') as file:\n",
    "                            file.write(new_data)\n",
    "                    #копирование файлов\n",
    "                    new_file = shutil.copy(os.path.join(root, file), destination_directoryLabels + 'instance' + str(counter) +'.txt')\n",
    "                    new_file1 = shutil.copy(os.path.join(root, file1), destination_directoryImages + 'instance' + str(counter) +'.jpg')\n",
    "                    counter+=1\n",
    "                    new_uid = file1[:-3]\n",
    "print('повторений:' + str(doppel_counter))\n",
    "print('всего:' + str(counter))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a932859f-060b-4b1b-b083-0ce6577d7fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#рандомное разбиение датасема\n",
    "\n",
    "dataset_dir = 'C:/Users/RD/WorkWork/Prog/Datasets/yolov5'\n",
    "images_dir = os.path.join(dataset_dir, 'images_all')\n",
    "labels_dir = os.path.join(dataset_dir, 'labels_all')\n",
    "output_dirs = {\n",
    "    'train': os.path.join(dataset_dir, 'train'),\n",
    "    'val': os.path.join(dataset_dir, 'val'),\n",
    "    'test': os.path.join(dataset_dir, 'test')\n",
    "}\n",
    "split_ratios = [0.8, 0.1, 0.1]\n",
    "random_seed = 42\n",
    "\n",
    "\n",
    "for key, output_dir in output_dirs.items():\n",
    "    os.makedirs(os.path.join(output_dir, 'images'), exist_ok=True)\n",
    "    os.makedirs(os.path.join(output_dir, 'labels'), exist_ok=True)\n",
    "\n",
    "\n",
    "image_files = sorted([f for f in os.listdir(images_dir) if f.endswith('.jpg')])\n",
    "label_files = sorted([f for f in os.listdir(labels_dir) if f.endswith('.txt')])\n",
    "\n",
    "\n",
    "assert len(image_files) == len(label_files), \"Количество изображений и меток должно совпадать\"\n",
    "\n",
    "# Разделяем на train и временный (val + test)\n",
    "train_images, temp_images, train_labels, temp_labels = train_test_split(\n",
    "    image_files, label_files, test_size=(split_ratios[1] + split_ratios[2]), random_state=random_seed)\n",
    "\n",
    "# Разделяем временный на val и test\n",
    "val_images, test_images, val_labels, test_labels = train_test_split(\n",
    "    temp_images, temp_labels, test_size=split_ratios[2] / (split_ratios[1] + split_ratios[2]), random_state=random_seed)\n",
    "\n",
    "\n",
    "def copy_files(file_list, src_dir, dst_dir):\n",
    "    for file_name in file_list:\n",
    "        shutil.copy(os.path.join(src_dir, file_name), os.path.join(dst_dir, file_name))\n",
    "\n",
    "\n",
    "copy_files(train_images, images_dir, os.path.join(output_dirs['train'], 'images'))\n",
    "copy_files(train_labels, labels_dir, os.path.join(output_dirs['train'], 'labels'))\n",
    "\n",
    "copy_files(val_images, images_dir, os.path.join(output_dirs['val'], 'images'))\n",
    "copy_files(val_labels, labels_dir, os.path.join(output_dirs['val'], 'labels'))\n",
    "\n",
    "copy_files(test_images, images_dir, os.path.join(output_dirs['test'], 'images'))\n",
    "copy_files(test_labels, labels_dir, os.path.join(output_dirs['test'], 'labels'))\n",
    "\n",
    "print(\"Датасет успешно разбит на train, val и test с использованием seed!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (DefineTheLoad___yolov5)",
   "language": "python",
   "name": "definetheload___yolov5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
